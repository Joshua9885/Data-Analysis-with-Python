{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SjH2ronADZO7oF7Cxf_PzM8LeknxDDKw","timestamp":1709287549099}],"mount_file_id":"17f9MNDtOiJDxTtNyfK4BGkRsPrUMZv8b","authorship_tag":"ABX9TyOmRpm8nGsRAEcjvnVDgsZw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import SimpleRNN,Dense,Embedding\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical"],"metadata":{"id":"FZ9tPPtwUOli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Generating some example sequential data\n","sentences=['I love My mom','I love my dady','I hate school','Today topic is RNN']"],"metadata":{"id":"bHGiFrqqVvCk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tkoenizing the words\n","tokenizer=Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","total_words=len(tokenizer.word_index)+1\n","print(total_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RUskicZ2W-7n","executionInfo":{"status":"ok","timestamp":1709287830181,"user_tz":-330,"elapsed":363,"user":{"displayName":"Sai CM-001","userId":"01017323947395288251"}},"outputId":"a35d5e63-cf0c-457f-93fc-ee80aff7abe0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12\n"]}]},{"cell_type":"code","source":["# Creating input sequences and their corresponding next words\n","input_sequences = []\n","for sentence in sentences:\n","    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n","    for i in range(1, len(tokenized_sentence)):\n","        n_gram_sequence = tokenized_sentence[:i+1]\n","        input_sequences.append(n_gram_sequence)\n","input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZzMOiSIjYp18","executionInfo":{"status":"ok","timestamp":1709287832466,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sai CM-001","userId":"01017323947395288251"}},"outputId":"d4e7eff5-efc3-43cb-c3ed-7020b9b84471"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2],\n"," [1, 2, 3],\n"," [1, 2, 3, 4],\n"," [1, 2],\n"," [1, 2, 3],\n"," [1, 2, 3, 5],\n"," [1, 6],\n"," [1, 6, 7],\n"," [8, 9],\n"," [8, 9, 10],\n"," [8, 9, 10, 11]]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Padding sequences for consistent input size\n","max_sequence_length = max([len(seq) for seq in input_sequences])\n","input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length,padding='pre')"],"metadata":{"id":"Zu0asTBGZgk3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdXkd2WuaT7q","executionInfo":{"status":"ok","timestamp":1709287838510,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sai CM-001","userId":"01017323947395288251"}},"outputId":"802d2501-037b-420f-dd5c-7a123ade91a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0,  0,  1,  2],\n","       [ 0,  1,  2,  3],\n","       [ 1,  2,  3,  4],\n","       [ 0,  0,  1,  2],\n","       [ 0,  1,  2,  3],\n","       [ 1,  2,  3,  5],\n","       [ 0,  0,  1,  6],\n","       [ 0,  1,  6,  7],\n","       [ 0,  0,  8,  9],\n","       [ 0,  8,  9, 10],\n","       [ 8,  9, 10, 11]], dtype=int32)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Creating input and output data\n","X, y = input_sequences[:, :-1], input_sequences[:, -1]\n","y = to_categorical(y, num_classes=total_words)"],"metadata":{"id":"Y1rjPL4HaZl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Building a simple RNN model\n","model = Sequential()\n","model.add(Embedding(input_dim=total_words, output_dim=50, input_length=max_sequence_length-1))\n","model.add(SimpleRNN(100, return_sequences=True))\n","model.add(SimpleRNN(100))\n","model.add(Dense(total_words, activation='softmax'))"],"metadata":{"id":"M8lyJoMWapgH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compiling the model\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","#training Model\n","model.fit(X,y,epochs=50,verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9YWtYYHbCGm","executionInfo":{"status":"ok","timestamp":1709287851552,"user_tz":-330,"elapsed":4216,"user":{"displayName":"Sai CM-001","userId":"01017323947395288251"}},"outputId":"8a34de29-fb26-45b1-cdb9-55a57b42390f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 - 2s - loss: 2.4973 - accuracy: 0.0000e+00 - 2s/epoch - 2s/step\n","Epoch 2/50\n","1/1 - 0s - loss: 2.4178 - accuracy: 0.1818 - 13ms/epoch - 13ms/step\n","Epoch 3/50\n","1/1 - 0s - loss: 2.3398 - accuracy: 0.4545 - 12ms/epoch - 12ms/step\n","Epoch 4/50\n","1/1 - 0s - loss: 2.2612 - accuracy: 0.4545 - 14ms/epoch - 14ms/step\n","Epoch 5/50\n","1/1 - 0s - loss: 2.1807 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n","Epoch 6/50\n","1/1 - 0s - loss: 2.0974 - accuracy: 0.6364 - 13ms/epoch - 13ms/step\n","Epoch 7/50\n","1/1 - 0s - loss: 2.0110 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 8/50\n","1/1 - 0s - loss: 1.9221 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n","Epoch 9/50\n","1/1 - 0s - loss: 1.8317 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n","Epoch 10/50\n","1/1 - 0s - loss: 1.7413 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n","Epoch 11/50\n","1/1 - 0s - loss: 1.6520 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n","Epoch 12/50\n","1/1 - 0s - loss: 1.5647 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n","Epoch 13/50\n","1/1 - 0s - loss: 1.4791 - accuracy: 0.5455 - 12ms/epoch - 12ms/step\n","Epoch 14/50\n","1/1 - 0s - loss: 1.3949 - accuracy: 0.5455 - 11ms/epoch - 11ms/step\n","Epoch 15/50\n","1/1 - 0s - loss: 1.3120 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 16/50\n","1/1 - 0s - loss: 1.2309 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 17/50\n","1/1 - 0s - loss: 1.1532 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 18/50\n","1/1 - 0s - loss: 1.0804 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 19/50\n","1/1 - 0s - loss: 1.0139 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 20/50\n","1/1 - 0s - loss: 0.9543 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 21/50\n","1/1 - 0s - loss: 0.9019 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 22/50\n","1/1 - 0s - loss: 0.8561 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 23/50\n","1/1 - 0s - loss: 0.8166 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 24/50\n","1/1 - 0s - loss: 0.7827 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 25/50\n","1/1 - 0s - loss: 0.7536 - accuracy: 0.6364 - 11ms/epoch - 11ms/step\n","Epoch 26/50\n","1/1 - 0s - loss: 0.7284 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 27/50\n","1/1 - 0s - loss: 0.7055 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 28/50\n","1/1 - 0s - loss: 0.6841 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 29/50\n","1/1 - 0s - loss: 0.6637 - accuracy: 0.6364 - 13ms/epoch - 13ms/step\n","Epoch 30/50\n","1/1 - 0s - loss: 0.6449 - accuracy: 0.6364 - 13ms/epoch - 13ms/step\n","Epoch 31/50\n","1/1 - 0s - loss: 0.6279 - accuracy: 0.6364 - 13ms/epoch - 13ms/step\n","Epoch 32/50\n","1/1 - 0s - loss: 0.6129 - accuracy: 0.6364 - 12ms/epoch - 12ms/step\n","Epoch 33/50\n","1/1 - 0s - loss: 0.5990 - accuracy: 0.6364 - 13ms/epoch - 13ms/step\n","Epoch 34/50\n","1/1 - 0s - loss: 0.5857 - accuracy: 0.7273 - 11ms/epoch - 11ms/step\n","Epoch 35/50\n","1/1 - 0s - loss: 0.5723 - accuracy: 0.7273 - 12ms/epoch - 12ms/step\n","Epoch 36/50\n","1/1 - 0s - loss: 0.5586 - accuracy: 0.7273 - 12ms/epoch - 12ms/step\n","Epoch 37/50\n","1/1 - 0s - loss: 0.5451 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n","Epoch 38/50\n","1/1 - 0s - loss: 0.5319 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n","Epoch 39/50\n","1/1 - 0s - loss: 0.5193 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n","Epoch 40/50\n","1/1 - 0s - loss: 0.5070 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n","Epoch 41/50\n","1/1 - 0s - loss: 0.4945 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n","Epoch 42/50\n","1/1 - 0s - loss: 0.4819 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n","Epoch 43/50\n","1/1 - 0s - loss: 0.4694 - accuracy: 0.8182 - 16ms/epoch - 16ms/step\n","Epoch 44/50\n","1/1 - 0s - loss: 0.4573 - accuracy: 0.8182 - 15ms/epoch - 15ms/step\n","Epoch 45/50\n","1/1 - 0s - loss: 0.4458 - accuracy: 0.8182 - 11ms/epoch - 11ms/step\n","Epoch 46/50\n","1/1 - 0s - loss: 0.4349 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n","Epoch 47/50\n","1/1 - 0s - loss: 0.4246 - accuracy: 0.8182 - 18ms/epoch - 18ms/step\n","Epoch 48/50\n","1/1 - 0s - loss: 0.4149 - accuracy: 0.8182 - 13ms/epoch - 13ms/step\n","Epoch 49/50\n","1/1 - 0s - loss: 0.4056 - accuracy: 0.8182 - 12ms/epoch - 12ms/step\n","Epoch 50/50\n","1/1 - 0s - loss: 0.3970 - accuracy: 0.8182 - 17ms/epoch - 17ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7e625034fdc0>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Generating text using the trained model\n","seed_text = input(\"Enter the starting word: \")\n","next_words = int(input(\"Enter how many words to predict: \"))\n","\n","for _ in range(next_words):\n","    tokenized_seed = tokenizer.texts_to_sequences([seed_text])[0]\n","    tokenized_seed = pad_sequences([tokenized_seed], maxlen=max_sequence_length-1, padding='pre')\n","    predicted_word_index = np.argmax(model.predict(tokenized_seed), axis=-1)\n","    predicted_word = tokenizer.index_word[predicted_word_index[0]]\n","    seed_text += \" \" + predicted_word\n","\n","print(seed_text)"],"metadata":{"id":"QLP-ZZ4mcCMN"},"execution_count":null,"outputs":[]}]}